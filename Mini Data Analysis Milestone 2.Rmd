---
title: "Mini Data Analysis Milestone 2"
author: "April Hwang"
output: html_document
---

###knit to an `.md` file by changing the output in the YAML header to `github_document`, before submitting a tagged release on canvas.*

###submit a link to your tagged release on canvas.

#load data and tidyverse package

```{r, message = FALSE}
library(datateachr)
library(tidyverse)
```

# Task 1: Process and summarize your data 

### 1.1 (1 point): Write research questions from milestone 1

**Research question 1** : What, if any, is the relationship between time and allowance of pet ownership in this dataset? Similarly, is there any relationship between time and availability of accessible parking?

**Research question 2** : Is there a relationship between the number of units and the number of storeys? 

**Research question 3** : What are the variables for which information is most readily available (i.e. no missing data) and least readily available (i.e. large amount of missing data)?

**Research question 4** : What are the top three most popular building amenities? 


### 1.2 (8 points)

Now, for each of your four research questions, choose one task from options 1-4 (summarizing), and one other task from 4-8 (graphing). You should have 2 tasks done for each research question (8 total). Make sure it makes sense to do them! (e.g. don't use a numerical variables for a task that needs a categorical variable.). Comment on why each task helps (or doesn't!) answer the corresponding research question.

Ensure that the output of each operation is printed!

**Summarizing:**

1.  Compute the *range*, *mean*, and *two other summary statistics* of **one numerical variable** across the groups of **one categorical variable** from your data.
2.  Compute the number of observations for at least one of your categorical variables. Do not use the function `table()`!
3.  Create a categorical variable with 3 or more groups from an existing numerical variable. You can use this new variable in the other tasks! *An example: age in years into "child, teen, adult, senior".*
4. Compute the proportion and counts in each category of one categorical variable across the groups of another categorical variable from your data. Do not use the function `table()`!

**Graphing:**

6. Create a graph of your choosing, make one of the axes logarithmic, and format the axes labels so that they are "pretty" or easier to read.

7. Make a graph where it makes sense to customize the alpha transparency.

Using variables and/or tables you made in one of the "Summarizing" tasks: 

8. Create a graph that has at least two geom layers. 
9. Create 3 histograms, with each histogram having different sized bins. Pick the "best" one and explain why it is the best.

Make sure it's clear what research question you are doing each operation for!

<!------------------------- Start your work below ----------------------------->

**Research question 1** : What, if any, is the relationship between time and allowance of pet ownership in this dataset? Similarly, is there any relationship between time and availability of accessible parking?

*Summarizing*: Create a categorical variable with 3 or more groups from an existing numerical variable.

I will create a new categorical variable (year_level) which identifies the century in which the building was built. 

```{r}
apt_buildings %>%
  mutate(year_level = case_when(year_built < 1901 ~ '19th century',
                                year_built < 2001 ~ '20th century', 
                                TRUE ~ '21st century'))
```

*Graphing*: Create a graph that has at least two geom layers.

I will create a graph with year_level (the same variable that I made in the above summarizing task) on the x-axis and no_of_accessible_parking_spaces on the y-axis. I will use geom_boxplot() and geom_jitter(). I will also remove a few extreme outliers which may be potential errors as they indicate over 150 accessible parking spaces.

```{r}
apt_buildings %>%
  mutate(year_level = case_when(year_built < 1901 ~ '19th century',
                                year_built < 2001 ~ '20th century', 
                                TRUE ~ '21st century')) %>%
  ggplot(aes(x = year_level, y = no_of_accessible_parking_spaces)) + 
  geom_boxplot(colour = 'grey') +
  geom_jitter(alpha = 0.2, colour = 'steelblue') + 
  scale_y_log10('no_of_accessible_parking_spaces') +
  theme_classic()

```


**Research question 2** : Is there a relationship between the number of units and the number of storeys?

*Summarizing*: Create a categorical variable with 3 or more groups from an existing numerical variable.

I will create a new categorical variable (_rise_level_) which classifies each building as low-rise, mid-rise or high-rise. For this exercise, low-rise buildings will be defined as buildings with 10 floors or under. Mid-rise buildings are defined as buildings that have between 11 to 15 floors. High-rise buildings are defined as buildings that have 16 floors or above.  

```{r}
apt_buildings %>%
  mutate(rise_level = case_when(no_of_storeys < 11 ~ 'low-rise',
                                no_of_storeys < 16 ~ 'mid-rise', 
                                TRUE ~ 'high-rise'))
```


*Graphing*:Create a graph that has at least two geom layers. 

I will be creating a graph using geom_jitter() and geom_smooth(), incorporating the variable created above, _rise_level_. I will remove one outlier which is listed as having over 4000 units, which may be an error.


```{r}
apt_buildings %>%
  mutate(rise_level = case_when(no_of_storeys < 11 ~ 'low-rise',
                                no_of_storeys < 16 ~ 'mid-rise', 
                                TRUE ~ 'high-rise')) %>%
  ggplot(aes(x = no_of_units, y = no_of_storeys, colour = rise_level)) + 
  geom_jitter(outlier.shape = NA, alpha = 0.2) +
  coord_cartesian(xlim =  c(0, 700)) +
  geom_smooth() +
  theme_classic()

```


```{r}

###use for another task
apt_buildings %>%
  ggplot(aes(x = year_built, y = no_of_units)) + 
  geom_point(outlier.shape = NA, alpha = 0.2, colour = 'blue') +
  coord_cartesian(ylim =  c(0, 800)) +
  geom_smooth(colour ='black') +
  theme_classic()

```

**Research question 3** : What are the variables for which information is most readily available (i.e. no missing data) and least readily available (i.e. large amount of missing data)?

###
*Summarizing*: Compute the number of observations for at least one of your categorical variables

For this task, I will compute the NA counts of each level of the all the columns in _apt_buildings_. I will also count the total number of levels as a reference to better answer the reserch question in the future.

```{r}
#count NA and tidy data
apt_buildings_NA <- apt_buildings %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>% 
  pivot_longer(cols = everything(), names_to = 'col_name', values_to = 'NA_count') 

print(apt_buildings_NA)

#convert apt_building_NA to fct and count levels
as.factor(apt_buildings_NA$col_name) %>%
  nlevels()

```


###
*Graphing*: Create a graph of your choosing, make one of the axes logarithmic, and format the axes labels so that they are "pretty" or easier to read.

```{r}

#count NA, tidy data and arrange in descending order
apt_buildings_NA <- apt_buildings %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>% 
  pivot_longer(cols = everything(), names_to = 'col_name', values_to = 'NA_count') %>%
  arrange(desc(NA_count))

print(apt_buildings_NA)

#create bar graph for 5 columns with the highest number of NA values
apt_buildings_NA %>%
  slice_max(NA_count, n = 5) %>%

  #shorten column names to fit graph
  mutate(col_name = fct_recode(col_name, 
                               'prop_management' = 'prop_management_company_name',
                               'accessible_parking' = 'no_of_accessible_parking_spaces',
                               'barrier_free_accessible_units' = 'no_barrier_free_accessible_units')) %>%

  #plot point graph in descending order
  ggplot(aes(x = fct_rev(fct_reorder(col_name, NA_count)), y = NA_count)) +
  geom_col(fill = 'steelblue') +
  scale_x_discrete(guide = guide_axis(n.dodge=2)) +
  ggtitle('Columns with Highest NA Count') +
  xlab('Column') + 
  ylab('NA count') +
  theme_minimal()


```


**Research question 4** : What are the top three most popular building amenities? 

*Summary* Compute the number of observations for at least one of your categorical variables.

For this task, I will convert the _amenities_ variable to a factor, then compute the counts of each level. Then I will tidy the data by converting each cell into a single value. For this research question, popularity of the amenities will be quantified by its frequency.

```{r}
#convert amenities to factor
amenities_fct <- as.factor(apt_buildings$amenities) 

#compute counts of each level
amenities_count <- fct_count(amenities_fct) 

#convert each cell into single value
amenities_count %>%
  separate(f, into = c('f1','f2','f3', 'f4','f5','f6'), sep = ' , ') %>% #convert each cell to single value
  pivot_longer(c('f1','f2','f3', 'f4','f5','f6'), names_to = 'f', values_to = 'amenities_type') %>% #place amenities in single variable
  select(amenities_type) %>% #show only amenities type
  na.omit() %>% #omit NA 
  count(amenities_type) #count each amenity type

```


*Graphing* Create a graph of your choosing, make one of the axes logarithmic, and format the axes labels so that they are "pretty" or easier to read.

For this task, I will use the new tibble from the summary task to create a bar graph which shows frequency of each type of amenities. The y-axis will be logarithmic, and the axes will be labeled as 'Type' and 'Frequency'. There will also ensure that there is no overlapping of the x-axis label text.

```{r}
#convert amenities to factor
amenities_fct <- as.factor(apt_buildings$amenities)

#compute counts of each level
amenities_count <- fct_count(amenities_fct) 

#convert each cell into single value
amenities_count %>%
  separate(f, into = c('f1','f2','f3', 'f4','f5','f6'), sep = ' , ') %>% #convert each cell to single value
  pivot_longer(c('f1','f2','f3', 'f4','f5','f6'), names_to = 'f', values_to = 'amenities_type') %>% #place amenities in single variable
  select(amenities_type) %>% #show only amenities type
  na.omit() %>% #omit NA 
  
  #create bar graph in ascending order
  ggplot(aes(x = fct_rev(fct_infreq(amenities_type)))) +
  geom_bar(fill = 'steelblue', width = 0.9) +
  scale_x_discrete(guide = guide_axis(n.dodge=2)) +
  ggtitle('Amenity Type Frequency') +
  xlab('Type') + 
  ylab('Frequency') +
  theme_minimal()


```





<!----------------------------------------------------------------------------->

### 1.3 (2 points)

Based on the operations that you've completed, how much closer are you to answering your research questions? Think about what aspects of your research questions remain unclear. Can your research questions be refined, now that you've investigated your data a bit more? Which research questions are yielding interesting results?

<!------------------------- Write your answer here ---------------------------->


<!----------------------------------------------------------------------------->

# Task 2: Tidy your data 

In this task, we will do several exercises to reshape our data. The goal here is to understand how to do this reshaping with the `tidyr` package.

A reminder of the definition of *tidy* data:

-   Each row is an **observation**
-   Each column is a **variable**
-   Each cell is a **value**

### 2.1 (2 points)

Based on the definition above, can you identify if your data is tidy or untidy? Go through all your columns, or if you have \>8 variables, just pick 8, and explain whether the data is untidy or tidy.

<!--------------------------- Start your work below --------------------------->

_apt_building_ is untidy for the following reasons:
- _amenities_ contains multiple measurements 
- _bike_parking_ contains multiple measurements 
- _parking_type_ contains multiple measurements 
- _facilities_available_ contains multiple measurements 

<!----------------------------------------------------------------------------->

### 2.2 (4 points)

Now, if your data is tidy, untidy it! Then, tidy it back to it's original state.

If your data is untidy, then tidy it! Then, untidy it back to it's original state.

Be sure to explain your reasoning for this task. Show us the "before" and "after".

<!--------------------------- Start your work below --------------------------->


Before (untidy):
```{r}
apt_buildings_fct <- apt_buildings %>% mutate(across(where(is_character),as_factor)) #convert chr to fct

levels(apt_buildings_fct$facilities_available) 
```



After (tidy then untidy):
```{r}
apt_buildings_fct <- apt_buildings %>% mutate(across(where(is_character),as_factor)) #convert chr to fct

#levels(apt_buildings_fct$facilities_available) #check for types of facilities

#tidy facilities_available  
apt_buildings_tidy <- apt_buildings_fct %>%
    mutate(facilities_available = fct_recode(facilities_available, 
                                           'Compost' = 'Green Bin / Organics',
                                           'NA' = 'Unknown',
                                           'NA' = 'Not Available'))

#check that data is tidy
print(select(apt_buildings_tidy,facilities_available))

#untidy facilities_available

apt_buildings_untidy <- apt_buildings_fct %>%
    mutate(facilities_available = fct_recode(facilities_available, 
                                           'Green Bin / Organics' = 'Compost',
                                           'Unknown' = 'NA',
                                           'Not Available' = 'NA'))

#check that data is tidy
print(select(apt_buildings_untidy,facilities_available))

```

Reasoning for this task:

<!----------------------------------------------------------------------------->

### 2.3 (4 points)

Now, you should be more familiar with your data, and also have made progress in answering your research questions. Based on your interest, and your analyses, pick 2 of the 4 research questions to continue your analysis in the remaining tasks:

<!-------------------------- Start your work below ---------------------------->

1.  What are the variables for which information is most readily available (i.e. no missing data) and least readily available (i.e. large amount of missing data)?

2.  Is there a relationship between the number of units and the number of storeys?

<!----------------------------------------------------------------------------->

Explain your decision for choosing the above two research questions.

<!--------------------------- Start your work below --------------------------->

<!----------------------------------------------------------------------------->

Now, try to choose a version of your data that you think will be appropriate to answer these 2 questions. Use between 4 and 8 functions that we've covered so far (i.e. by filtering, cleaning, tidy'ing, dropping irrelevant columns, etc.).

(If it makes more sense, then you can make/pick two versions of your data, one for each research question.) 

<!--------------------------- Start your work below --------------------------->

# Task 3: Modelling

## 3.0 (no points)

Pick a research question from 1.2, and pick a variable of interest (we'll call it "Y") that's relevant to the research question. Indicate these.

<!-------------------------- Start your work below ---------------------------->

**Research Question**: Is there a relationship between the number of units and the number of storeys?

**Variable of interest**: Number of units

<!----------------------------------------------------------------------------->

## 3.1 (3 points)

Fit a model or run a hypothesis test that provides insight on this variable with respect to the research question. Store the model object as a variable, and print its output to screen. We'll omit having to justify your choice, because we don't expect you to know about model specifics in STAT 545.

Hypothesis: There will be a positive correlation between the number of storeys and the number of units.

I will fit a model that makes predictions on the number of units using the number of storeys by using the `lm()` function.


<!-------------------------- Start your work below ---------------------------->

```{r}

#prep data using 4-8 functions
apt_buildings_unit_storeys <- apt_buildings %>%
  
  #use select() to drop irrelevant columns
  select(no_of_storeys, no_of_units) %>% 
  
  #use arrange() to reorder rows 
  relocate(no_of_units) %>%
  
  #use desc() to sort rows in descending order
  arrange(desc(no_of_units)) %>%

  #use rename() to shorten column labels
  rename(storeys = no_of_storeys,
         units = no_of_units) %>%
  
  #use slice() to remove first outlier row with 4000+ units
  slice(-1)

print(apt_buildings_unit_storeys)

#linear regression modeling

apt_buildings_unit_storeys %>%
  ggplot(aes(x = storeys, y = units)) +
    geom_point(colour = 'steelblue') +
    geom_smooth(method = 'lm', colour = 'black') +
    theme_minimal()

```


<!----------------------------------------------------------------------------->

## 3.2 (3 points)

Produce something relevant from your fitted model: either predictions on Y, or a single value like a regression coefficient or a p-value.

-   Be sure to indicate in writing what you chose to produce.
-   Your code should either output a tibble (in which case you should indicate the column that contains the thing you're looking for), or the thing you're looking for itself.
-   Obtain your results using the `broom` package if possible. If your model is not compatible with the broom function you're needing, then you can obtain your results by some other means, but first indicate which broom function is not compatible.

<!-------------------------- Start your work below ---------------------------->

<!----------------------------------------------------------------------------->

# Task 4: Reading and writing data

Get set up for this exercise by making a folder called `output` in the top level of your project folder / repository. You'll be saving things there.

## 4.1 (3 points)

Take a summary table that you made from Task 1, and write it as a csv file in your `output` folder. Use the `here::here()` function.

-   **Robustness criteria**: You should be able to move your Mini Project repository / project folder to some other location on your computer, or move this very Rmd file to another location within your project repository / folder, and your code should still work.
-   **Reproducibility criteria**: You should be able to delete the csv file, and remake it simply by knitting this Rmd file.

<!-------------------------- Start your work below ---------------------------->

<!----------------------------------------------------------------------------->

## 4.2 (3 points)

Write your model object from Task 3 to an R binary file (an RDS), and load it again. Be sure to save the binary file in your `output` folder. Use the functions `saveRDS()` and `readRDS()`.

-   The same robustness and reproducibility criteria as in 4.1 apply here.

<!-------------------------- Start your work below ---------------------------->

<!----------------------------------------------------------------------------->

# Overall Reproducibility/Cleanliness/Coherence Checklist 

Here are the criteria we're looking for.

## Coherence (0.5 points)

The document should read sensibly from top to bottom, with no major continuity errors. 

The README file should still satisfy the criteria from the last milestone, i.e. it has been updated to match the changes to the repository made in this milestone. 

## File and folder structure (1 points)

You should have at least three folders in the top level of your repository: one for each milestone, and one output folder. If there are any other folders, these are explained in the main README.

Each milestone document is contained in its respective folder, and nowhere else.

Every level-1 folder (that is, the ones stored in the top level, like "Milestone1" and "output") has a `README` file, explaining in a sentence or two what is in the folder, in plain language (it's enough to say something like "This folder contains the source for Milestone 1").

## Output (1 point)

All output is recent and relevant:

-   All Rmd files have been `knit`ted to their output md files. 
-   All knitted md files are viewable without errors on Github. Examples of errors: Missing plots, "Sorry about that, but we can't show files that are this big right now" messages, error messages from broken R code
-   All of these output files are up-to-date -- that is, they haven't fallen behind after the source (Rmd) files have been updated.
-   There should be no relic output files. For example, if you were knitting an Rmd to html, but then changed the output to be only a markdown file, then the html file is a relic and should be deleted.

Our recommendation: delete all output files, and re-knit each milestone's Rmd file, so that everything is up to date and relevant.

## Tagged release (0.5 point)

You've tagged a release for Milestone 2. 

### Attribution

Thanks to Victor Yuan for mostly putting this together.